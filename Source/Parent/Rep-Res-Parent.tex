%%%%%%%%%%%%%%%
% Parent document for the book Reproducible Research with R and RStudio
% Christopher Gandrud
% Updated: 22 August 2012
%%%%%%%%%%%%%%
% !Rnw weave = knitr


\documentclass[ChapterTOCs,krantz1]{krantz}\usepackage{graphicx, color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\definecolor{fgcolor}{rgb}{0.2, 0.2, 0.2}
\newcommand{\hlnumber}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlfunctioncall}[1]{\textcolor[rgb]{0.501960784313725,0,0.329411764705882}{\textbf{#1}}}%
\newcommand{\hlstring}[1]{\textcolor[rgb]{0.6,0.6,1}{#1}}%
\newcommand{\hlkeyword}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlargument}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hlcomment}[1]{\textcolor[rgb]{0.180392156862745,0.6,0.341176470588235}{#1}}%
\newcommand{\hlroxygencomment}[1]{\textcolor[rgb]{0.43921568627451,0.47843137254902,0.701960784313725}{#1}}%
\newcommand{\hlformalargs}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hleqformalargs}[1]{\textcolor[rgb]{0.690196078431373,0.250980392156863,0.0196078431372549}{#1}}%
\newcommand{\hlassignement}[1]{\textcolor[rgb]{0,0,0}{\textbf{#1}}}%
\newcommand{\hlpackage}[1]{\textcolor[rgb]{0.588235294117647,0.709803921568627,0.145098039215686}{#1}}%
\newcommand{\hlslot}[1]{\textit{#1}}%
\newcommand{\hlsymbol}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlprompt}[1]{\textcolor[rgb]{0.2,0.2,0.2}{#1}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfigure}
%\usepackage{epsfig}
\usepackage{makeidx}
%\usepackage{showidx}
\usepackage{multicol}
\frenchspacing
\tolerance=5000

\usepackage{dcolumn}
\usepackage{booktabs}
\usepackage{url}
\usepackage{todonotes}
\usepackage{tikz}




\makeatletter


\makeatother

\makeindex

\begin{document}



\title{Reproducible Research with R and RStudio}

\author{Christopher Gandrud}

\maketitle

\frontmatter

{\chapter*{Author}}

\contributor{Christopher Gandrud}{Yonsei University}{Wonju, Republic of Korea}




\chapter*{Forward}

FILL IN



\chapter*{Preface}

FILL IN


\chapter*{Stylistic Conventions}\label{StylisticConventions}
\begin{noindent}




\input{/git_repositories/Rep-Res-Book/Temp/StyleTemp.tex}

%<<ChildStylisticConventionDelete>>=
%unlink("/git_repositories/Rep-Res-Book/temp.tex")
%@
\end{noindent}

\listoffigures
\listoftables
\tableofcontents

\mainmatter

\setcounter{page}{1}

\part{Getting Started}

% Chapter Chapter 1 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 2 August 2012




\chapter{Introducing Reproducible Research}

FILL IN

\section{What is reproducible research?}

\section{Why should research be reproducible?}

Incorporating high reproducibility into your research is important for science and it also makes the research process easier for the researcher. 

\subsection{For Science}

\subsection{For You}

Working to make your research reproducible from the start makes the research process easier. A third person may or may not actually reproduce your research even if you make it easy to do so. But, it's almost certain that you will reproduce parts or even all of your research. Virtually no actual research process is completely linear. We almost never gather data, run our analyses, and present our results without also going backwards to add variables, make changes to our statistical models, create new graphs, and so on. Whether these changes are because of journal reviewers' or conference participants comments or we discovery that new and better data has been made available since beginning the project, designing our research to be reproducible from the start makes it much easier to make these changes.

Changes made to one part of a research project have a way of cascading through the other parts. For example, adding a new variable to a largely completed analysis requires gathering new data and merging it into existing data sets. If we are using data imputation or matching methods this can lead to adjustments to the entire data set. We then have to update our statistical models and the tables and graphs we use to present results. Adding a new variable essentially forces us to reproduce large portions of our research. If we made it easier for others do reproduce our research we also made it easier for us to do this. 

COMPLETE

\section{Who should read this book?}

\subsection{Students}

\subsection{Researchers}

\subsection{Industry practitioners}

\section{Why use R/RStudio for reproducible research?}

\paragraph{R}
Why use a statistical programming language like R for reproducible research? R is more than just a statistics program, like \index{SAS}, Stata, or SPSS. It can be used to integrate all stages of the research process not just the statistical analysis stage. COMPLETE

The way we interact with R or any other programming and markup language promotes reproducibility more than our interactions with Graphical User Interface (GUI) programs like SPSS\footnote{I know you can write scripts in statistical programs like SPSS, but doing so is not encouraged by the interface and we often have to learn multiple languages just to write scripts that run analyses, create graphics, and deal with matrices.} and Microsoft Word. When we write (and save) R code we are being forced to explicitly express the steps we take to accomplish a goal in an easily documented way. When we achieve a goal by clicking through drop down menus in GUI programs, the steps we take are lost. To document them requires considerable extra effort.

\paragraph{RStudio}
Why use an Integrated Development Environment (IDE), especially RStudio for reproducible research? RStudio allows us to have all of the R's advantages, but in a more visually navigable way. Think of it a as happy medium between R's text-based interface and a pure GUI. COMPLETE

RStudio also has a very tight integration with technologies such as {\tt{knitr}} and \LaTeX that makes the presentation of reproducible presentation of results. 

\subsection{Complete integration of data gathering, analysis, and
presentation.}

\subsubsection{Presentation}

There are many \LaTeX editors available, both open source and paid, as
well as other ways to compile \LaTeX documents, including directly
through the command line. \textbf{R} is capable of compiling
\LaTeX documents through .

\textbf{RStudio} is actually as a very nice \LaTeX editor. For creating
documents that integrate markup and \textbf{R} code, at the moment it
pretty much can't be beat. It has full syntax highlighting, even for
documents with \texttt{knitr} code (which it can collapse when you just
want to work on the text). It can spell check \LaTeX documents. It
handles \texttt{knitr} code chunks beautifully making it easy to
navigate through complex documents and run individual chunks.

Even if you aren't creating documents that integrate \textbf{R} code,
\emph{R} is still a decent full functioning \LaTeX editor. It can insert
common commands like \texttt{\textbackslash{}section*\{\}} for
unnumbered sections. Most importantly it easily compile \LaTeX documents
and show you a preview.

\section{Book overview}

\subsection{What this book is not.}\label{WhatNot}

This book describes a workflow for reproducible research primarily using
R and RStudio. It is designed to give you the
necessary tools to use this workflow for your own research. It is not
designed to be a complete introduction to R, RStudio,
GitHub, the command line, or any other program that is a part
of this workflow. Instead it shows you how these tools can fit together
to make your√ü research more reproducible.

To get the most out of these individual programs I point you to other
resources that cover these programs in more detail.

That being said, my goal in this for this book to be self-sufficient to
the extent that a reader without a detailed understanding of these
programs will be able to understand and use the commands and procedures
I cover in this book. While learning how to use R and the other
programs I often encountered examples that included commands, variables,
and other things that were not well explained in the texts that I was
reading. This caused me to waste many hours trying to figure out, for
example, what the \texttt{\$} is used for (preview: it's the 'component selector'). I hope to save
you from this wasted time by either providing a brief explanation of
these possibly frustratingly mysterious conventions and/or pointing you
in the direction of a good explanation.

To that end, I can recommend a number of books for that cover more of
the nitty-gritty of R and the command line.

\begin{itemize}
\item
  Michael J. Crawley's encyclopaedic R book, appropriately
  titled, \textbf{The R Book} published by Wiley.
\item
  Norman Matloff's tour through the programming language aspects of
  R called \textbf{The Art of R Programming: A Tour of
  Statistical Design Software} published by No Starch Press.
\item
  For an excellent introduction to the command line in Linux and Mac,
  though with pretty clear implications for Windows users if they are
  running PowerShell (see Chapter 2) see William E. Shotts
  Jr.'s book \emph{The Linux Command Line: A Complete Introduction} also
  published by No Starch Press.
\item
  The RStudio website (\url{http://rstudio.org/docs/}) has a
  number of useful tutorials on how to use \texttt{knitr} with
  \LaTeX and Markdown.
\end{itemize}
\subsection{How to read this book.}

This book tells a story. It has a beginning, middle, and end. So, unlike
a reference book it can and should be read like a novel, taking you
through an empirical research processes from an empty folder maybe
called \texttt{Research Paper} to a completed set of documents that
showcase your findings.

That being said, readers with more experience using tools like
R or \LaTeX) may want to
skip over the nitty-gritty parts of the book that describe how to
manipulate data frames or compile a \LaTeX) document into a PDF. Please feel free to do
this.

If you are experienced with R in particular you may want to
skip over Chapter 3: Getting Started with R/RStudio.

\subsection{How this book was written}

This book practices what it preaches. It can be reproduced. It was
written using the programs and methods that it describes. Full
documentation and source files can be found at the Book's
\textbf{GitHub} repository.

Feel free to read and even copy (within reason and with attribution, of
course) the Book's source code. You can find it at
\url{https://github.com/christophergandrud/Rep-Res-Book}. This is
especially useful if you want to know how to do something in the book
that I don't directly cover in the text.

In the same spirit, I encourage you to make your research files--not
just data, but analysis code and markup--available for other researchers
to learn from.

Not only does reproducibility help us evaluate past work, but it also
pushes forward knowledge in the scientific community.

\subsection{Contents overview.}

% Chapter Chapter 2 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 




\chapter{Getting Started with Reproducible Research}

\section{The Big Picture: A workflow for reproducible research}

\subsection{Data Gathering}

\subsection{Data Analysis}

\subsection{Data Presentation}

\section{Practical tips for reproducible research}

To help you  is good to keep a few over

\subsection{Document everything!}

In order to reproduce your research others must be able to know what you did. You have to tell them what you did by documenting as much of your research process as possible. Ideally, you should tell your readers how you gathered your data, analyzed it, and presented the results.

The other tips and Many of the other One important part of documenting everything with R is to \emph{record your \index{session info}}. Many things in R stay the same over time, which makes it easy for future researchers to recreate what was done in the past. However, things--syntax in particular--do can change from one version of R to another. Also, the way R functions may be handled slightly different on different operating systems. Finally, you may have R set to load packages by default. These packages might be necessary to run your code, but other people might not be able know what packages were loaded from just looking at your source code. The \texttt{sessionInfo} command prints a record of all of these things. The information from the session I used to create this book up until this chapter is:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{sessionInfo}()
\end{alltt}
\begin{verbatim}
## R version 2.15.1 (2012-06-22)
## Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
## 
## locale:
## [1] C/en_US.UTF-8/C/C/C/C
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets 
## [6] methods   base     
## 
## other attached packages:
## [1] knitr_0.7
## 
## loaded via a namespace (and not attached):
## [1] digest_0.5.2   evaluate_0.4.2 formatR_0.6   
## [4] plyr_1.7.1     stringr_0.6.1  tools_2.15.1  
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent It is good practice to include make output of the session info available either in the main document or in a separate text file. If you want to nicely format the information for a \LaTeX document simply use the {\tt{toLatex}} command.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{toLatex}(\hlfunctioncall{sessionInfo}())
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Otherwise, you can use the {\tt{print}} command. 

\subsection{All files should be human readable}

Treat all of your research documents as if someone who has not worked on the project will try to read them and understand them. Computer code is a way of communicating with the computer. It is `machine readable' in that the computer is able to use it to understand what we want done.\footnote{Of course, if it does not understand it will usually give us an error message.} Hopefully, the researcher understands what they are communicating when they write their code. However, there is a very good chance that other people (or the researcher six months in the future) will not understand what is being communicated. So, you need to make your documentation `human readable'. To make your documentation accessible to other people you need to {\bf{comment frequently}} and {\bf{format your code using a style guide}}. 

\paragraph{Commenting}
In R everything on a line after a {\tt{#}} hash (number) character is ignored by R, but is readable to people who open the file. This is called a \index{comment declaration} You can use the {\tt{#}} to place comments telling other people what you are doing.\footnote{The hash character is also used this way in shell scripts.} Here are some examples:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# A complete comment line}
2 + 2  \hlcomment{# A comment after R code}
\end{alltt}
\begin{verbatim}
## [1] 4
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent In \LaTeX everything after the {\tt{\%}} percent sign is treated as a comment and in markdown/HTML comments are placed inside of {\tt{\textless !-- --\textgreater}}.

\paragraph{Style guides}
In natural language writing you don't necessarily need to follow a \index{style guide} for things such as punctuation. People could probably figure out what you are saying. But it would be a lot easier for your readers if you use consistent rules. The same is true when writing R code. It's good to follow consistent rules for formatting your code so that:

\begin{itemize}
    \item it's easier for others to understand,
    \item it's easier for you to understand.
\end{itemize}

There are a number of R style guides. Most of them are similar to the Google R Style Guide (\url{http://google-styleguide.googlecode.com/svn/trunk/google-r-style.html}). Hadley Wickham has a nicely presented style guide. You can find it at \url{https://github.com/hadley/devtools/wiki/Style}. You can use the package \index{\tt{formatR}} to automatically reformat your code so that it is easier to read.

\subsection{Work hard so you can be lazy}

\subsection{Everything is a (text) file}

\subsection{Research projects are many files tied together}

\subsection{Have a plan to organize, store, and make your files
available}

\section{The tools of reproducible research covered in this book}

\subsection{R/RStudio}

\subsection{\texttt{knitr}}

\subsection{Cloud storage \& versioning}

\subsection{The command line}

\subsection{Markup languages: \LaTeX \& Markdown/HTML}

% Chapter Chapter 3 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 22 August 2012




\chapter{Getting Started with R and RStudio}

If you have rarely or never used R before the first two sections of this chapter give you enough information that you should be able to get started and understand the code I use in this book. For more details about R please refer to the related resources I mentioned in chapter \ref{WhatNot}. Experienced R users might want to skip the first two sections of the chapter. This chapter also gives a brief overview of RStudio. It highlights the key features of main RStudio panel (what appears when you open RStudio) and some of its key features for reproducible research.

\section{Installing R and RStudio}

R and RStudio are open source programs and can be easily downloaded for free. Both are available for Windows, Mac, and Unix. They should run well on most modern computers. 

You should install R before installing RStudio. You can down load the programs from the following websites:

\begin{itemize}
    \item {\bf{R}}: \url{http://www.r-project.org/},
    \item {\bf{RStudio}}: \url{http://rstudio.org/download/}.
\end{itemize}

\noindent The download webpages for these programs have comprehensive information on how to install them, so please refer to those pages for more information.

\paragraph{Installing markup languages}

If you are planning on creating \LaTeX documents you need to install a \index{\LaTeX distribution}. They are also open source and available for Windows, Mac, and Unix. They can be found at: \url{http://www.latex-project.org/ftp.html}. Please refer to that site for more installation information.

If you want to create markdown documents you will need to install the the \index{{\emph{markdown}} package} in R. You can do this the same way that you install any package in R, with the {\tt{install.packages}} command.\footnote{The exact command is: {\tt{install.packages("markdown")}}.} 

\section{Using R: the basics}

\subsection{Objects \& Assignment}

\subsection{Component Selection}

\subsection{Functions, Commands, and Arguments}

\section{Using RStudio}

When you first open RStudio you should get a something that looks like Figure \ref{BlankMain}. In this figure you see three panels. The large one on the left is the {\emph{Console}}. This pane functions exactly the same as 

\begin{figure}[t]
    \caption{RStudio Startup Panel}
    \label{BlankMain}

    \includegraphics[width = \textwidth]{/git_repositories/Rep-Res-Book/Source/Children/Chapter3/images3/BlankMainPanel.png}
\end{figure}


\section{Tips}

Here are a few tips that make using R and RStudio a little easier.

\paragraph{Autocomplete}

In R and RStudio you do not have to type out every command, argument, or object name. On Mac and Unix based versions of R after you start typing a command or object name you can hit the ``tab" key to automatically complete what you are typing. The \index{autocomplete} function is particularly good in RStudio. Not only does it give you a list of words to choose from, but it also shows you an abbreviated version of the help file for commands and arguments.

% Chapter Chapter 4 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 




\chapter{Chapter 4:}


\part{Data Gathering and Storage}

% Chapter Chapter 5 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 26 July 2012




\chapter{Gathering Data with R}

There are many practical issues involved in gathering data that can make replication easier or harder. As with all of the steps in this book: document everything. Replication will be easier if your documentation--source code--can be understood and executed by a computer. Of course there are data gathering situations that simply require manually pointing and clicking, talking with subjects in an experiment, and so on. The best we can do in these situations is just describe our data gathering process in detail CITE. Nonetheless, R's automated data gathering capabilities are extensive and often under utilized. Learning how to take full advantage of them greatly increases replicability and can even save researchers considerable time and effort.

\section{Organize Your Data Gathering}

Before getting into the details of using R to automate data gathering, lets's start from where all data gathering should start: a plan to organize the process. Clearly organizing your data gathering process from the start of a research project improves the possibility of replicability and can save significant effort over the course of the project. 

A key principle of replicable data gathering with R, like replicable research in general is segmenting the process into discrete files that can be run by a common Make file. The Make file's output is the data set(s) that we use in the statistical analyses. There are two types of files that the Make file runs: data clean up files and merging files. Data clean up files bring raw (the rawer the better) individual data sources into R and transform them into something that can be merge with data from the other sources. Some of the R tools for data clean up were covered in Chapter 3. In this chapter we mostly cover the ways to bring raw data into R. We don't explicitly cover the process of merging data sets together in this book GET CITE. Merging files are executed by the Make file after it runs the clean up files.

Data gathering Make files usually only need one or two commands {\tt{setwd}} and {\tt{source}}. As we talked about in the previous chapter, {\tt{setwd}} simply tells R where to look for and place files. {\tt{source}} tells R to run code in some file.\footnote{The {\tt{source}} command is used more in the Chapter 8.} 

If we plan to gather data from two different data sources--DATA1 and DATA2--stored in the directory DIRECTORY our Make file might look like this:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Example Make file}
\hlfunctioncall{setwd}(\hlstring{"~/DIRECTORY/"})

\hlcomment{# Clean up raw data files.}
\hlfunctioncall{source}(\hlstring{"CleanDATA1.R"})
\hlfunctioncall{source}(\hlstring{"CleanDATA2.R"})
    
\hlcomment{# Merge cleaned data files}
\hlfunctioncall{source}("MergeDATA1.DATA2.R)
\end{alltt}
\end{kframe}
\end{knitrout}


You can save the output data set using the {\tt{write.table}} command placed in the merge file or the Make file.

\section{Importing locally stored data sets}

\subsection{Single files}

\subsection{Looping through multiple files}

\section{Importing data sets from the internet}

\subsection{Data from non-secure ({\tt{http}}) URLs}

\subsection{Data from secure ({\tt{https}}) URLs}

\subsection{Compressed data stored online}

Sometimes data files can be very large, making them difficult to store and download without compressing them. There are a number of compression methods such as Zip and tar archives. Zip files have the extension {\tt{.zip}} and tar archives use extensions such as {\tt{.tar}} and {\tt{.gz}}. In most cases\footnote{Some formats that require the {\emph{foreign}} package to open are more difficult. This is because functions such as {\tt{read.dta}} for opening Stata {\tt{.dta}} files only accept file names or URLs as arguments, not connections, which we create for unzipped files.} we can easily download, decompress, and create dataframe objects from these files directly in {\bf{R}}. 

To do this we need to:\footnote{The description of this process is based on a Stack Overflow comment by Dirk Eddelbuettel (see {\url{http://stackoverflow.com/questions/3053833/using-r-to-download-zipped-data-file-extract-and-import-data?answertab=votes\#tab-top}}, accessed 16 July 2012.}

\begin{itemize}
    \item create a temporary file with {\tt{tempfile}} to store the zipped file which we will remove with the {\tt{unlink command}} at the end,
    \item download the file with {\tt{download.file}},
    \item decompress the file with one of the {\tt{connections}} commands in {\emph{base}} {\bf{R}},\footnote{To find a full list of commands type {\tt{?connections}} in to the {\bf{R}} console.}
    \item read the file with {\tt{read.table}}. 
\end{itemize}

The reason that we have to go through so many extra steps is that compressed files are more than just a single file, but can contain more than one file as well as metadata.

Let's download a compressed file called {\emph{uds\_summary.csv}} from \cite{Pemstein2010}. It is in a zipped file called {\emph{uds\_summary.csv.gz}}. The file's URL address is {\url{http://www.unified-democracy-scores.org/files/uds_summary.csv.gz}}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# For simplicity, store the URL in an object called \hlstring{'url'}.}
url <- \hlstring{"http://www.unified-democracy-scores.org/files/uds_summary.csv.gz"}

\hlcomment{# Create a temporary file called \hlstring{'temp'} to put the zip file}
\hlcomment{# into.}
temp <- \hlfunctioncall{tempfile}()

\hlcomment{# Download the compressed file into the temporary file.}
\hlfunctioncall{download.file}(url, temp)
\end{alltt}
\begin{flushleft}\ttfamily\noindent\textcolor{warningcolor}{\#\# Warning: unable to resolve \\ 
\#\# 'www.unified-democracy-scores.org'}\end{flushleft}\begin{flushleft}\ttfamily\noindent\bfseries\textcolor{errorcolor}{\#\# Error: cannot open URL \\ 
\#\# 'http://www.unified-democracy-scores.org/files/uds\_summary.csv.gz'}\end{flushleft}\begin{alltt}

\hlcomment{# Decompress the file and convert it into a dataframe class}
\hlcomment{# object called \hlstring{'data'}.}
data <- \hlfunctioncall{read.csv}(\hlfunctioncall{gzfile}(temp, \hlstring{"uds_summary.csv"}))
\end{alltt}
\begin{flushleft}\ttfamily\noindent\textcolor{warningcolor}{\#\# Warning: seek on a gzfile connection returned an internal \\ 
\#\# error}\end{flushleft}\begin{flushleft}\ttfamily\noindent\bfseries\textcolor{errorcolor}{\#\# Error: no lines available in input}\end{flushleft}\begin{alltt}

\hlcomment{# Delete the temporary file.}
\hlfunctioncall{unlink}(temp)
\end{alltt}
\end{kframe}
\end{knitrout}


\subsection{Data APIs \& feeds}

There are growing number of commands that can gather data directly from
their sources and import them into \textbf{R}. Needless to say, this is
great for reproducible research since it not only makes the data
gathering process easier (you don't have to download a ton of Excel
files and fiddle around with them before even getting the data into
\textbf{R}), but it also makes replicating the data gathering process
much more straightforward. Some examples include:

\begin{itemize}
    \item The \emph{openair} package, which beyond providing a number of tools for analysing air quality data also has the ability to directly gather data directly from sources such as Kings College London's London Air (\url{http://www.londonair.org.uk/}) database with the \texttt{importKCL} command.
\end{itemize}

\section{Basic web scraping}

\subsection{Scraping tables}

\subsection{Gathering and parsing text}

% Chapter Chapter 6 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 




\chapter{Storing, Collaborating, Accessing Files, Versioning}\label{Storing}

A stumbling block to actually reproducing a piece of research is getting a hold of the datasets and the codebooks that describe the data used in
an analysis.

Researchers often face a number of data management issues that, beyond
making their research difficult to reproduce, can make doing the initial
research difficult.

First, there is the problem of \textbf{storing} the data so that it is
protected against computer failure--virus infections, spilling coffee on
your laptop, and so on.

Fourth, we almost never create a data set or write a paper perfectly all
at once. We may make changes and then realize that we liked an earlier
version, or parts of an earlier version better. This is a particularly
important issue in data management where we may transform our data in
unintended ways and want to go back to an earlier version. Collaborative
projects can have regular incidents of one author accidentally deleting
something in a file that another author needed, for example.

To deal with these issues we need to store our data in a system that has
\textbf{version control}. Version control systems keep track of changes
we make to our files and allow us to access previous versions if we
like.

the data set can often grow and become disorganized. Perhaps even during
a data transformation This creates problems

You can solve all of these problems in a couple of different ways using
free or low cost cloud-based storage formats. In this chapter we will
learn how to use Dropbox and GitHub for data:

\begin{itemize}
    \item storage,
    \item accessing,
    \item collaboration,
    \item version control.
\end{itemize}

\section{Saving data in reproducible formats}

Before getting into the details of cloud-based data storage, lets just
consider what type of formats you should actually save your data in. A
key issue for reproducibility is that others be able to not only get
ahold of the exact data you used in your analysis, but be able to
understand and use the data not only now, but in the future. Some file
formats make this easier than others.

R is able to read (and write) a very wide variety of file
formats, mostly through the \texttt{foreign} package in \texttt{base}
R. This includes

\section{Storing data in the cloud}

Storing data locally--on your computer--or on a flash drive is generally
more prone to loss than storing data on remote servers, often referred
to as `the cloud'.

\section{Dropbox}

The easiest types of cloud storage for your research are services like
Dropbox and Google Drive. These services typically
involve a folder based on your computer's hard drive that is
automatically synced with a similar folder on a cloud-based server.
Typically you can sign up for the service for free and receive a limited
amount of storage space (usually a few gigabytes, which should be plenty
if your research is made up of text files.).

Most of these services not only store your data in the cloud, but also
provide some way to share files and maybe even includes basic version
control. I am going to focus on using Dropbox because it
currently offers a complete set of features that allow you to store,
version, collaborate, and access your data.

\subsection{Version control}

Dropbox has a simple version control system. Every time you
save a document on Dropbox a new version is created. One the
Dropbox website

\subsection{Accessing Data}

There are two similar, but importantly different ways to access data
stored on Dropbox. All files stored on Dropbox have a
URL address through which they can be access from computer connected to
the internet. Some of these files can be easily loaded directly into
R, while others must me manually (point-and-click) downloaded
onto your computer and then loaded into R. The key factor is
whether or not the files are located in your \textbf{Dropbox}'s
\emph{Public} folder. Files in the \emph{Public} folder can be
downloaded directly into R. Files not in the \emph{Public} folder
have to be downloaded manually.\footnote{This is not completely true. It
  is possible to create a web scraper (see Chapter GET) that could
  download a data file from a file not in your \emph{Public} folder.
  However, this is kind of a hassle and not practical, especially since
  the accessing files from the \emph{Public} folder is so easy.}

Either way you find a file's URL address by first right-clicking on the
file icon in you Dropbox folder. If the file is stored in the
\emph{Public} folder, you go to Dropbox then \textbf{Copy
Public Link}. This copies the URL into your clipboard from where you can
paste it into your R source code (or wherever). Once you have
the URL you can load the file directly into R using the
\texttt{read.table} command for dataframes (see Chapter 5) or the \texttt{source}
command for source files (see Chapter 8).

If the file is not in your \emph{Public} folder you also go to
Dropbox after right-clicking. Then choose \textbf{Get Link}.
This will open a webpage in your default web browser from where you can
download the file. You can copy and paste the page's URL from your
browser's address bar.

You can also get these URL links through the online version of your
Dropbox. First log into the Dropbox website. When you
hover your curser over a file (or folder) name you will see a chain icon
appear on the far right. Clicking on this icon will get you the link.

Storing files in the \emph{Public} folder clearly makes replication
easier because the files can be downloaded and run directly in
R.

Note that you cannot save files through the URL link. You must save
files in the Dropbox folder on your computer.

\section{GitHub}

Dropbox does a fine job of meeting our four basic criteria for
reproducible data storage. GitHub meets these criteria and
more.

GitHub was not explicitly designed to host research projects or
even data. It was designed to host `socially coded' computer programs.
It built an interface on top of the git version control system
that makes it easy relatively easy for a number of collaborators to work
together to build a computer program. This seems very far from
reproducible research.

However, remember that as reproducible researchers we are just building
projects out of interconnected text files. This is exactly the same as
computer programming. and like computer programers, we need ways to
store, version control, access, and collaborate on our text files.
Because GitHub is very actively used by people with very
similar needs (who are also really good programmers), the interface
offers many highly developed and robust features for reproducible
researchers.

As is usually the case, GitHub's added features mean that it is
takes a longer time than Dropbox to set up and become familiar.
So we need good reasons to want to invest the time needed to learn
GitHub rather than just sticking with Dropbox or a
similar service. Here is a list of GitHub's key features
relative to Dropbox for reproducible research:

\begin{itemize}
\item
  Git is directly integrated into RStudio projects
  (\textbf{RStudio} also supports the subversion version
  control system, but I don't cover that here).
\item
  Dropbox's version control system only lets you the see the
  file names, the times they were created, who created them, and revert
  back to specific versions. git tracks every change you make
  in a way that makes it relatively easy to find the version you want.
  The GitHub website and GUI programs for Mac and Windows
  provide nice interfaces for examining specific changes. You can also
  use the command line to see changes.
\item
  Dropbox creates a new version every time you save a file,
  which can make it difficult to actually find the version you want.
  git's version control system only creates a new version when
  you tell it to.
\item
  Dropbox does not merge conflicting versions of a file
  together. This can be annoying when you are collaborating on project
  and more than one author is making changes to documents.
  GitHub identifies conflicts and lets you reconcile them.
\item
  The GitHub website as an `'Issues'' area where you can to
  note and discuss issues you have while doing your research. Basically
  this is an interactive to-do list for your research project.
\end{itemize}

\subsection{Setting Up GitHub}

There are a number of ways to set up GitHub on your computer. I
will briefly cover both the command line version (available for Windows,
Mac, and Linux) and the GUI\footnote{Graphical User Interface, i.e.~not
  the command line version, but the one with windows that you navigate
  with your mouse.} version currently available only for Windows and
Mac.

\subsection{Version Control in GitHub}

GitHub's version control system is much more comprehensive than Dropbox's. However, it also has a steeper learning curve.

\paragraph{Reverting to an old version of a file}

You can use the {\tt{git checkout}} command to revert to a previous version of a document, because you accidentally deleted something important or made other changes you don't like. To 'checkout' a particular version of a file type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
git checkout COMMITREF FILENAME
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent Now the previous version of the file is in your working directory, where you can commit it as usual.

Let's break down the code.  {\tt{FILENAME}} is the name of the file that you want to change\footnote{If it is in a repository's subdirectory you will need to include this in the file name.} and {\tt{COMMITREF}} is the reference that git gave to the commit you want to revert back to. The reference is easy to find and copy in GitHub. On the file's GitHub page click on the {\tt{History}} button. This will show you all of the commits. By clicking on {\tt{Browse Code}} you can see what the file at that commit looks like. Above this button is another with a series of numbers and letters. This is the commit's SHA (Secure Hash Algorithm). For our purposes, it is the commit's reference number. Click on the {\tt{Copy SHA}} button to the left of the SHA to copy it. You can then paste it as an argument to your {\tt{git checkout}} command. 

\paragraph{More Practice with Command Line GitHub}

If you want more practice setting up GitHub in the command
line, GitHub and the website Code School have an interactive
tutorial that you might find interesting. You can find it at:
\url{http://try.github.com/levels/1/challenges/4}.
% Chapter Chapter 7 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 




\chapter{Chapter 7:}



\part{Analysis and Results}

% Chapter Chapter 8 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 




\chapter{Statistical Modelling and knitr}

\section{Incorporating analyses into the markup}

\subsection{Full code in the main document}

\subsubsection{\LaTeX  }

\subsubsection{Markdown}

\subsection{Showing code \& results inline}

Sometimes we want to have some R code or output to show up in the text of our documents. We may want to include stylized code in our text when we discuss how we did an analysis. We may want to report the mean of some variable in our text.

\subsubsection{LaTeX}

\paragraph{Inline static code}

If we just want to include a code snippet in out text we can simply use the \LaTeX command  \texttt{\textbackslash{}tt}. This sets our text to `typewriter' font, the standard font for inline code in \LaTeX (I use it in this book, as you have probably noticed).

\paragraph(Inline dynamic code}

If we want to dynamically show the results of some R code in our text we can use the  \texttt{\textbackslash Sexpr} command. This is a pseudo \LaTeX command. Its structure is more like a \LaTeX command's structure than \texttt{knitr} in that we enclose our R code in curly brackets (\texttt{\{\}}) rather than the usual \texttt{\textless\textless\textgreater\textgreater= . . . @} syntax for code chunks.

For example, imagine that we wanted to include the mean--591--in the text of our document. The {\emph{rivers}} numeric vector, loaded by default in R, has the length of 141 major rivers recorded in miles. We can simply use the {\tt{mean}} command to find the mean and the {\tt{round}} command to round it to the nearest whole number:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{round}(\hlfunctioncall{mean}(rivers), digits = 0)
\end{alltt}
\begin{verbatim}
## [1] 591
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent To have just the output show up inline with the text of our document we would type something like:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
The mean length of 141 major rivers in North America
is \textbackslash{}Sexpr\{\hlfunctioncall{round}(\hlfunctioncall{mean}(rivers), digits = 0)\} miles. 
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent This will produce the sentence:

\begin{quote}
    The mean length of 141 major rivers in North America is 591 miles. 
\end{quote}

\subsubsection{Markdown}

\paragraph{Inline static code}

To include static code inline in an R Markdown document we enclose the code in single backticks (\` \`). For example typing \`\ MeanRiver \textless- mean(rivers) \`\ produces {\tt{MeanRiver \textless- mean(rivers)}}.

\paragraph{inline dynamic code}

To include dynamic code in an R Markdown document we use the backticks as be fore but include a the letter \texttt{r} after the first one.

\subsection{Sourcing R code from another file}

There are a number of reasons that you might want to have your R source code located in a separate file from your markup even if you plan to compile them together with \emph{knitr}.

First, it can be unwieldy to edit both your markup and long R source code chunks in the same document, even with RStudio's handy \emph{knitr} code collapsing and chunk management options. There are just too many things going on in one document.

Second, you may want to use the same code in multiple documents--an
article and presentation for example. It is nice to not have to copy and
paste the same code into multiple places, but have multiple documents
link to the same source code. Plus if you make changes to the source
code, these changes will automatically be made across all of your
presentation documents. You don't need to make the same changes multiple
times.

Third, other researchers trying to replicate your work might only be
interested in specific parts of your analysis. If you have the analysis
broken into separate and clearly labeled files it is easier for these
researchers to find the specific bits of code that they are interested
compared to digging through long markup files.

\subsubsection{Source from a local file}

Usually in the early stages of research you may want to source analysis
files located on your computer. Doing this is simple. The \texttt{knitr}
syntax is the same as above. The only change is that instead of writing
all of our code in the chunk we save it to its own file and use the
\texttt{source} command in \emph{base} \textbf{R} to access it. For
example:

\subsubsection{Source from a non-secure URL (\texttt{http})}

Sourcing from your local computer is fine if you are working alone and do not want others to access your code. Once you start collaborating and generally wanting people to be able to replicate your code, you need to
use another method.\footnote{You can make the replication code accessible for download and either instruct others to change the working directory to the replication file or have them change the directory information as necessary. However, this usually just adds an extra complicating step that makes replication harder. It is also a   pain if you are collaborating and each author has to constantly change the directories.}

The simplest solution to these issues is to host the replication code in your \textbf{Dropbox} public folder. You can find the file's public URL the same way we did in Chapter 6. Now use the \texttt{source} command the same way as before. For example:

\subsubsection{Source from a secure URL (\texttt{https})}

If you are using \textbf{GitHub} or another service that uses secure
URLs the steps are generally the same, but you need to use the
\texttt{source\_url} command in the \emph{devtools} package. For
\textbf{GitHub} based source code we find the file's URL the same way we
did in Chapter 6. Remember to get the URL for the \emph{raw} version of
the file.

\section{Saving output objects for future use}

\section{Including highlighted syntax in the output}

\subsection{\LaTeX}

\subsection{Markdown/HTML}

\section{Debugging}

% Chapter Chapter 9 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 




\chapter{Showing Results with Tables}

Graphs and other visual methods, discussed in the next chapter, can
often be a more effective way to present results than tables.\footnote{This
  is especially true of the small-print, high-density coefficient
  estimate tables that are sometimes descriptively called `train
  schedule' tables.} Nonetheless, tables of results, descriptive statistics,
and so on can sometimes be an important part of communicating
research findings.

Creating tables by hand can be tedious no matter what program you are
using to type up your results. Even more tedious is making changes to
hand-created tables when you make changes to your data and models.
Creating these tables can actually introduce new
errors--post-analysis!--if you incorrectly copy what is in your
R output. This is a very real possibility. The mind can go numb
doing that sort of work. Also, creating tables by hand is not very
reproducible.

Fortunately, we don't actually need to create tables by hand. There are
many ways to have R do the work for us. The goal of this
chapter is to learn how to how to \textbf{automate table creation} for
documents produced with both \LaTeX and Markdown/HTML. There are a
number of ways to turn R objects into tables written in
\LaTeX or HTML markup. In this chapter I mostly focus on the
\texttt{xtable} and \texttt{texreg} packages. \texttt{xtable} can
created tables for both of these markup languages. \texttt{texreg} only
produces output for \LaTeX. \texttt{knitr} allows us to incorporate
these tables directly into our documents.

\textbf{Warning:} Automating table creation removes the possibility of
adding errors to our analyses by incorrectly copying R output,
which is a big potential problem in hand-created tables. Be warned, it
is not an error free process. We could easily create inaccurate tables
through coding errors. For example, we may incorrectly merge together
columns in so that our id variables no longer match the data they are
supposed to.

So, as always, it is important to `eyeball' the output. Does it make
sense? If we picked a couple values in the R output do the
match what is in our final table? If not, we need to go back to the code
and see where things have gone wrong. With that caveat, lets start
making tables.

\section{Table Basics}

Before getting into the details of how to create tables from R objects we need to first learn how generic tables are created in \LaTeX and Markdown/HTML.

\subsection{Tables in \LaTeX}

\subsection{Tables in Markdown/HTML}

\section{Creating tables from R objects}

\subsection{\texttt{xtable} \& \texttt{texreg} basics with supported
class objects}

\subsubsection{\texttt{xtable} for \LaTeX}

\subsubsection{\texttt{xtable} for Markdown}

\subsection{\texttt{xtable} with non-supported class objects}

{\tt{xtable}} and other commands in similar packages are very convenient for making tables from objects in supported classes.\footnote{To see a full list of classes that {\tt{xtable}} supports type {\tt{methods(xtable)}} into the R console.} With supported class objects {\tt{xtable}} knows where to look for the vectors containing the things--coefficient names, standard errors, and so on--that it needs to create the table. With unsupported classes, however, it doesn't know where to look for these things. We need to help it out. 

{\tt{xtable}} does have a way of dealing with {\tt{matrix}} and {\tt{dataframe}} class objects. The rows of these objects become the rows of the table and the columns become the table columns. So, to create tables with non-supported class objects we need to

\begin{enumerate}
    \item find and extract the information from the unsupported class object that we want in the table, 
    \item convert this information into a matrix or dataframe where the rows and columns of the object correspond to the rows and columns of the table that we want,
    \item use {\tt{xtable}} with this object to create the table.
\end{enumerate}

Imagine that we want to create a results table showing the covariate names, coefficient means, and quantiles for marginal posterior distributions from a Bayesian normal linear regression using the {\tt{zelig}} command \cite{Goodrich2007} and data from the {\emph{swiss}} dataframe.\footnote{This dataframe is loaded by default.} We run our model:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Load required library}
\hlfunctioncall{library}(Zelig)

\hlcomment{# Run model}
NBModel <- \hlfunctioncall{zelig}(Examination ~ Education, model = \hlstring{"normal.bayes"}, 
                    data = swiss, cite = FALSE)

\hlcomment{# Find NBModel's class}
\hlfunctioncall{class}(NBModel)
\end{alltt}
\begin{verbatim}
## [1] "MCMCZelig"
\end{verbatim}
\end{kframe}
\end{knitrout}


Using the {\tt{class}} command we found that the model output object is an {\tt{MCMCZelig}} class object. This class is not supported by {\tt{xtable}}. If we try to create a summary table called {\emph{NBTable}} of the results we will get the following error:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{flushleft}\ttfamily\noindent\bfseries\textcolor{errorcolor}{\#\# Error: no applicable method for 'xtable' applied to an \\ 
\#\# object of class "MCMCZelig"}\end{flushleft}\end{kframe}
\end{knitrout}


With unsupported class objects we have to create the summary ourselves and extract the things that we want from it manually. This is where a good knowledge of vectors comes in handy. 

First, let's create a summary of our output object {\emph{NBModel}}:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
NBModelSum <- \hlfunctioncall{summary}(NBModel)
\end{alltt}
\end{kframe}
\end{knitrout}


We created a new object of the class {\tt{summary.MCMCZelig}}. We're still not there yet as this object contains not just the covariate names and so on but also information we don't want to include in our results table like the formula that we used. The second step is to extract a matrix from inside {\emph{NBModelSum}} called {\emph{summary}} with the component selector ({\tt{\$}}). This matrix is where the things we want in our table are located. I find it easier to work with dataframes, so we'll also convert the matrix into a dataframe.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
NBSumDataFrame <- \hlfunctioncall{data.frame}(NBModelSum$summary)
\end{alltt}
\end{kframe}
\end{knitrout}

%%
\noindent Here is what our model results dataframe looks like:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
##                Mean      SD   X2.5.    X50.  X97.5.
## (Intercept) 10.1397 1.31673  7.5579 10.1566 12.7058
## Education    0.5786 0.09118  0.3963  0.5781  0.7609
## sigma2      34.9703 7.81260 22.9567 33.8782 53.2172
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent Now we have a dataframe object that {\tt{xtable}} can handle. After a little cleaning up (see the chapter's source code for more details) we can use {\emph{NBSumDataFrame}} with {\tt{xtable}} as before to create the following table:
\vspace{0.5cm}


% latex table generated in R 2.15.1 by xtable 1.7-0 package
% Wed Aug 22 19:10:51 2012
\begin{table}[ht]
\begin{center}
\begin{tabular}{rrrrr}
  \hline
 & Mean & 2.5\% & 50\% & 97.5\% \\ 
  \hline
(Intercept) & 10.14 & 7.56 & 10.16 & 12.71 \\ 
  Education & 0.58 & 0.40 & 0.58 & 0.76 \\ 
  sigma2 & 34.97 & 22.96 & 33.88 & 53.22 \\ 
   \hline
\end{tabular}
\caption{Coefficient Estimates Predicting Examination Scores in Swiss Cantons (1888) Found Using Bayesian Normal Linear Regression}
\end{center}
\end{table}




It may take a bit of hunting to find what you want, but a similar process can be used to create tables from objects of virtually any class.\footnote{This process can also be used to create graphics.} Hunting for what you want is generally easier by clicking on the object in RStudio's workspace pane.

\subsection{Basic \texttt{knitr} syntax for tables}

So far we have only looked at how to create \LaTeX and HTML tables from R objects. How can we knit these tables into our presentation documents?

The most important \texttt{knitr} chunk option for showing the markup created by these packages as tables is \texttt{results}. The \texttt{results} option can have three values:

\begin{itemize}
\item
  \texttt{markup},
\item
  \texttt{asis},
\item
  \texttt{hide}.
\end{itemize}
\texttt{hide} clearly hides the results of whatever we have in our code chunk; no results show up.

\section{Tables with \texttt{apsrtable}}


% Chapter Chapter 10 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 




\chapter{Chapter 10:}


\part{Presentation Documents}

% Chapter Chapter 11 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 




\chapter{Presenting with \LaTeX}

\section{The Basics}

\subsection{Editors}

\subsection{The Header}

\subsection{Headings}

\subsection{Footnotes \& Bibliographies}

\subsubsection{Footnotes}

Plain, non-bibliographic footnotes are easy to create in \LaTeX. Simply place \texttt{\textbackslash{}footnote\{} where you would like the footnote number to apear in the text. Then type in the footnote's text and of course remember to close it with a \texttt{\}}. \LaTeX does the rest, including formatting and numbering.

\subsubsection{Bibliographies}

\paragraph{Citing R Packages with BibTeX}

Researchers are pretty good about consistently citing others' articles and data. However, citing the R packages used in an analysis is very inconsistent. This is unfortunate not only because correct attribution is not being given but also because it makes reproducibility harder because it obscures important steps that were taken in the
research process. Fortunately, R actually includes the tools to quickly generate citations, including the version of the package you are using. It can also add them directly to an existing bibliography file.

You can automatically create citations for R packages using the \texttt{citation} command in \emph{base} R. For example if we want the citation information for the \texttt{Zelig} package we would simply type:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{citation}(\hlstring{"ggplot2"})
\end{alltt}
\begin{verbatim}
## 
## To cite ggplot2 in publications, please use:
## 
##   H. Wickham. ggplot2: elegant graphics for data
##   analysis. Springer New York, 2009.
## 
## A BibTeX entry for LaTeX users is
## 
##   @Book{,
##     author = {Hadley Wickham},
##     title = {ggplot2: elegant graphics for data analysis},
##     publisher = {Springer New York},
##     year = {2009},
##     isbn = {978-0-387-98140-6},
##     url = {http://had.co.nz/ggplot2/book},
##   }
## 
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent This gives us both the plain citation as well as the BibTeX version for use in \LaTeX and MultiMarkdown documents. If you only want the BibTeX version of the citation we can use the \texttt{toBibtex} command in the \emph{utils} package.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlfunctioncall{toBibtex}(\hlfunctioncall{citation}(\hlstring{"ggplot2"}))
\end{alltt}
\begin{verbatim}
## @Book{,
##   author = {Hadley Wickham},
##   title = {ggplot2: elegant graphics for data analysis},
##   publisher = {Springer New York},
##   year = {2009},
##   isbn = {978-0-387-98140-6},
##   url = {http://had.co.nz/ggplot2/book},
## }
\end{verbatim}
\end{kframe}
\end{knitrout}


\noindent You can append the citation to your existing BibTeX file using the \texttt{sink} command in \emph{base} R. This command diverts our output and/or the messages to a file. For example, imagine that our existing BibTeX file is called \texttt{biblio.bib}. To add the \emph{Zelig} package citation:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Divert output to biblio.bib}
\hlfunctioncall{sink}(file = \hlstring{"biblio.bib"}, 
     append = TRUE, type = \hlfunctioncall{c}(\hlstring{"output"})
     )      
\hlfunctioncall{toBibtex}(\hlfunctioncall{citation}(\hlstring{"ggplot2"})) \hlfunctioncall{sink}()
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent This places the citation at the end of our \texttt{biblio.bib} file. It is very important to include the argument \texttt{append = TRUE}. If you don't you will erase the existing file. The argument \texttt{type = c("output")} tells R to include only the output, not the messages.

An even faster way to add citations to a bibliography is with \texttt{write.bibtex} command in the \emph{knitcitations} package. To add the \emph{Zelig} citation to our \texttt{biblio.bib} file we only need to enter:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcomment{# Load package}
\hlfunctioncall{library}(knitcitations)
 
\hlcomment{# Write Zelig citation and}
\hlcomment{# to biblio.bib}
\hlfunctioncall{write.bibtex}(entry = \hlfunctioncall{c}(\hlstring{"ggplot2"}), 
              file = \hlstring{"bibliography.bib"}, append = TRUE)
\end{alltt}
\end{kframe}
\end{knitrout}


\noindent In Chapter 13 we'll look at the \texttt{knitcitations} package in more detail.
% Chapter Chapter 12 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 22 August 2012




\chapter{Large \LaTeX Documents: Theses, Books, \& Batch Reports}

\section{Planning large documents}

\subsection{Planning theses and books}

\subsection{Planning batch reports}


\section{Combining Chapters}

\subsection{Parent documents}

\subsection{Child documents}

\subsubsection{Child documents in the same format}

\subsubsection{Child documents in a different format}

You can use the \index{Pandoc} command line program and to convert child documents that are in a different markup language into the primary markup language you are using for your document. ADD DETAILS ON HOW TO INSTALL. If you have Pandoc installed on your computer, you can call it directly from your parent document with R's {\tt{system}} command. 

For example, the \ref{StylisticConventions} part of this book is written in Markdown. The file is called {\emph{StylisticConventions.md}} It was simply faster to write the list of conventions using the simpler Markdown syntax than \LaTeX, which as we saw has a more complicated way of creating lists. However, I want to include this list in my \LaTeX produced book. Pandoc can convert the Markdown document into a \LaTeX file. This file can then be input into my main document with the \LaTeX command {\tt{\\input}}.

Imagine that my parent and {\emph{StylisticConventions.md}} documents are in the same directory. In the parent document I added the following code to convert the Markdown syntax to \LaTeX and save it in a file called {\emph{StyleTemp.tex}}.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}
\begin{kframe}
\begin{verbatim}
%<<StyleTeX, echo=FALSE, results='hide'>>=
system("pandoc StylisticConventions.md
        -f markdown -t latex -o StyleTemp.tex",
        intern = TRUE)
%@
\end{verbatim}
\end{kframe}
\end{knitrout}

\section{Creating Batch Reports}

\subsection{stich}
% Chapter Chapter 13 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 




\chapter{Presenting on the Web and Beyond with Markdown/HTML}

\section{The Basics}

\subsection{Headings}

Headings in Markdown are extremely simple. To create a line in the style
of the topmost heading--maybe a title--just place one hash mark
(\texttt{\#}) at the beginning of the line. The second tier heading just
gets two hashes (\texttt{\#\#}) and so on. You can also put the hash
mark(s) at the end of the heading, but this is not necessary.

\subsection{Footnotes and bibliographies with MultiMarkdown}

\subsection{Math}

\subsection{Drawing figures with CSS}

\section{Simple webpages}

\subsection{RPubs}

\subsection{Hosting webpages with Dropbox}

\section{Presentations with \texttt{Slidify}}

\section{Reproducible websites}

\subsection{Blogging with Tumblr}

\subsection{Jekyll-Bootstrap and GitHub}

see \url{http://jfisher-usgs.github.com/r/2012/07/03/knitr-jekyll/}

\subsection{Jekyll and Github Pages}

\section{Using Markdown for non-HTML output with Pandoc}

Markdown syntax is very simple. So simple, you may be tempted to write many or all of your presentation documents in Markdown. This presents the obvious problem of how to convert your markdown documents to other markup languages if, for example, you would want to create a \LaTeX formatted PDF. 

Pandoc can help solve this problem. Pandoc is a command line program that can convert files written in Markdown, HTML, \LaTeX, and a number of other markup languages\footnote{See the Pandoc website for more details: {\url{http://johnmacfarlane.net/pandoc/}}} to any of the other formats. 

To use Pandoc first install it by following the instructions at {\url{http://johnmacfarlane.net/pandoc/installing.html}}. Luckily you do not need to open a shell window in addition to {\bf{R}} to run Pandoc. Instead you can run all Pandoc commands in {\bf{R}} with the the {\tt{system}} command. 

For example, 

%% Fill In Example with Fake Documents.

  
% Chapter Chapter 14 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 




\chapter{Chapter 14:}



\bibliographystyle{plain}
\bibliography{/git_repositories/Rep-Res-Book/Source/rep-res-book.bib}

\clearpage
\printindex

\end{document}

