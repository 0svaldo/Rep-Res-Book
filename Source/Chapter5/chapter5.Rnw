% Chapter Chapter 5 For Reproducible Research in R and RStudio
% Christopher Gandrud
% Created: 16/07/2012 05:45:03 pm CEST
% Updated: 

\chapter{Chapter 5: Gathering Data with R}

\section{Importing locally stored data sets}

\subsection{Single files}

\subsection{Looping through multiple files}

\section{Importing data sets from the internet}

\subsection{Data from non-secure (\texttt{http}) URLs}

\subsection{Data from secure (\texttt{https}) URLs}

\subsection{Data APIs \& feeds}

There are growing number of commands that can gather data directly from
their sources and import them into \textbf{R}. Needless to say, this is
great for reproducible research since it not only makes the data
gathering process easier (you don't have to download a ton of Excel
files and fiddle around with them before even getting the data into
\textbf{R}), but it also makes replicating the data gathering process
much more straightforward. Some examples include:

\begin{itemize}
\item
  The \emph{openair} package, which beyond providing a number of tools
  for analysing air quality data also has the ability to directly gather
  data directly from sources such as Kings College London's London Air
  (\url{http://www.londonair.org.uk/}) database with the
  \texttt{importKCL} command.
\end{itemize}
\section{Basic web scraping}

\subsection{Scraping tables}

\subsection{Gathering and parsing text}

